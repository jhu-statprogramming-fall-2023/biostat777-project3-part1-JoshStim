[{"path":"/articles/Example_analysis.html","id":"aims","dir":"Articles","previous_headings":"","what":"Aims","title":"Example Analysis","text":"analysis, seek demonstrate use leaps package, answer following questions superbowl commercials: common superbowl commercial attributes, vary usage time within brands? commercial attributes associated higher favorability? extent superbowl commercial favorability vary time brands? Using multiple linear regression, can identify significant predictors commercial favorability? Note using commercial’s like--dislike ratio youtube quantify favorability.","code":""},{"path":"/articles/Example_analysis.html","id":"load-data","dir":"Articles","previous_headings":"","what":"Load Data","title":"Example Analysis","text":"data analysis Five-Thirty-Eight -way-TidyTuesday. TidyTuesday link provides access TidyTuesday github repository well data dictionary used analysis.","code":"if (!dir.exists(here(\"vignettes\",\"data\"))) {      dir.create(here(\"vignettes\", \"data\"))   tuesdata <- tidytuesdayR::tt_load(2021, week = 10)   youtube.raw <- tuesdata$youtube   write.csv(youtube.raw, here(\"vignettes\", \"data\",\"youtube.csv\"))    } else{      youtube.raw <- read.csv(here(\"vignettes\", \"data\",\"youtube.csv\"))    }  glimpse(youtube.raw) #> Rows: 247 #> Columns: 26 #> $ X                         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1… #> $ year                      <int> 2018, 2020, 2006, 2018, 2003, 2020, 2020, 20… #> $ brand                     <chr> \"Toyota\", \"Bud Light\", \"Bud Light\", \"Hynudai… #> $ superbowl_ads_dot_com_url <chr> \"https://superbowl-ads.com/good-odds-toyota/… #> $ youtube_url               <chr> \"https://www.youtube.com/watch?v=zeBZvwYQ-hA… #> $ funny                     <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, … #> $ show_product_quickly      <lgl> FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE,… #> $ patriotic                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ celebrity                 <lgl> FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE… #> $ danger                    <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE,… #> $ animals                   <lgl> FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE,… #> $ use_sex                   <lgl> FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL… #> $ id                        <chr> \"zeBZvwYQ-hA\", \"nbbp0VW7z8w\", \"yk0MQD5YgV8\",… #> $ kind                      <chr> \"youtube#video\", \"youtube#video\", \"youtube#v… #> $ etag                      <chr> \"rn-ggKNly38Cl0C3CNjNnUH9xUw\", \"1roDoK-SYqSp… #> $ view_count                <int> 173929, 47752, 142310, 198, 13741, 23636, 30… #> $ like_count                <int> 1233, 485, 129, 2, 20, 115, 1470, 78, 342, 7… #> $ dislike_count             <int> 38, 14, 15, 0, 3, 11, 384, 6, 7, 0, 14, 0, 2… #> $ favorite_count            <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… #> $ comment_count             <int> NA, 14, 9, 0, 2, 13, 227, 6, 30, 0, 8, 1, 13… #> $ published_at              <chr> \"2018-02-03 11:29:14\", \"2020-01-31 21:04:13\"… #> $ title                     <chr> \"Toyota Super Bowl Commercial 2018 Good Odds… #> $ description               <chr> \"Toyota Super Bowl Commercial 2018 Good Odds… #> $ thumbnail                 <chr> \"https://i.ytimg.com/vi/zeBZvwYQ-hA/sddefaul… #> $ channel_title             <chr> \"Funny Commercials\", \"VCU Brandcenter\", \"Joh… #> $ category_id               <int> 1, 27, 17, 22, 24, 1, 24, 2, 24, 24, 24, 24,…"},{"path":"/articles/Example_analysis.html","id":"wrangle-data","dir":"Articles","previous_headings":"","what":"Wrangle data","title":"Example Analysis","text":", create 3 different data frames: youtube.mod: youtube.raw data frame, includes mutated columns like_to_dislike, view_count, view_group, view_factor, view_count_log10, like_to_dislike_log10. youtube.attr_by_year: summarizes commercial attributes favorability year youtube.attr_by_brand: summarizes commercial attributes favorability brand","code":"size_factor <- 1/2 youtube.mod <- youtube.raw %>%   mutate(like_to_dislike = (like_count + 1) / (dislike_count + 1),          view_group = case_when(view_count > 10 ** 6 ~ (size_factor)**0,          view_count > 10 ** 5 & view_count <= 10 ** 6 ~ (size_factor)**1,          view_count > 10 ** 4 & view_count <= 10 ** 5 ~ (size_factor)**2,          view_count > 10 ** 3 & view_count <= 10 ** 4 ~ (size_factor)**3,          view_count > 0 & view_count <= 10 ** 3 ~ (size_factor)**4)) %>%   mutate(view_factor = factor(view_group),          view_count_log10 = log10(view_count),          like_to_dislike_log10 = log10(like_to_dislike))  levels(youtube.mod$view_factor) <- c(\"views \\u2264 1,000\",                          \"1,000 < views \\u2264 10,000\",                          \"10,000 < views \\u2264 100,000\",                          \"100,000 < views \\u2264 1,000,000\",                          \"views > 1,000,000\")  youtube.attr_by_year <- split(youtube.mod, youtube.mod$year) %>%   map(function(x) summarize(x, n = n(),                             funny = mean(funny),                             celebrity = mean(celebrity),                             use_sex = mean(use_sex),                             spq = mean(show_product_quickly),                             patriotic = mean(patriotic),                             danger = mean(danger),                             animals = mean(animals),                             lltd = mean(like_to_dislike, na.rm = TRUE))) %>%   map_df(.f = ~.x, .id = \"year\") %>%   pivot_longer(cols = funny:animals, names_to = \"attribute\", values_to = \"relative_prop\")  youtube.attr_by_brand <- split(youtube.mod, youtube.mod$brand) %>%   map(function(x) summarize(x, n = n(),                             funny = mean(funny),                             celebrity = mean(celebrity),                             use_sex = mean(use_sex),                             spq = mean(show_product_quickly),                             patriotic = mean(patriotic),                             danger = mean(danger),                             animals = mean(animals),                             lltd = mean(like_to_dislike, na.rm = TRUE))) %>%   map_df(.f = ~.x, .id = \"brand\") %>%   pivot_longer(cols = funny:animals, names_to = \"attribute\", values_to = \"relative_prop\")"},{"path":[]},{"path":"/articles/Example_analysis.html","id":"how-common-are-superbowl-commercial-attributes-over-time-and-within-brands","dir":"Articles","previous_headings":"Analysis","what":"How common are superbowl commercial attributes over time and within brands?","title":"Example Analysis","text":"","code":"youtube.attr_by_year %>%   ggplot(aes(x = year, y = relative_prop, color = attribute, group = 1)) +   geom_line() +   facet_wrap(~attribute) +   labs(title = \"Trends in Commercial Attribute Use over Time\",        subtitle = \"Use of the 'funny' and 'sex' attributes in superbowl commercials is decreasing \\n over time, while the use 'celebrity' and 'patriotic' is rising.\",        x = \"Year\",        y = \"Relative Proportion\",        caption = \"Units on the x-axis are discrete. Line plots were used for the ease of viewing.\") +   scale_x_discrete(breaks=seq(2000,2020,5)) +   theme_bw() +   theme(legend.position = \"none\",         text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.x = element_text(size = 12),         axis.text.y = element_text(size = 12))  youtube.attr_by_brand %>%   ggplot(aes(x = attribute, y = brand, fill = relative_prop)) +   geom_tile() +   scale_fill_gradient(low = \"white\", high = \"red\") +   geom_text(aes(label=round(relative_prop,2)), colour = \"black\", check_overlap = TRUE) +   labs(title = \"Proportion of Brand's Commericials exhibiting Attribute\",        subtitle = \"Within brands, 'Funny' and 'Shows product quickly' (spq) are among the most \\n common commercial attributes.\",        x = \"Commercial Attribute\",        y = \"Brand\",        fill = \"Relative Proportion\",        caption = \"Tile colors represent the proportion of a brand's \\n commercials containing the given attribute.\") +   theme_bw() +   theme(text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.x = element_text(size = 12),         axis.text.y = element_text(size = 12))"},{"path":"/articles/Example_analysis.html","id":"which-commercial-attributes-are-associated-with-higher-favorability","dir":"Articles","previous_headings":"Analysis","what":"Which commercial attributes are associated with higher favorability?","title":"Example Analysis","text":"","code":"youtube.mod %>%   select(funny, show_product_quickly, patriotic, animals, danger,           celebrity, use_sex, like_to_dislike) %>%   pivot_longer(cols = funny:use_sex,                names_to = \"attribute\",                values_to = \"value\") %>%   ggplot(aes(x = value, y = like_to_dislike, fill = attribute)) +   geom_boxplot(outlier.shape = NA) +   geom_jitter(width = 0.15, alpha = 0.25, size = 1) +   stat_summary(fun = \"mean\", color = \"white\", shape = 3) +   scale_y_continuous(trans = 'log10') +   facet_wrap(~attribute) +   labs(title = \"Commercial Favorability by Attribute\",        subtitle = \"'Celebrity' and 'Danger' are associated with greater mean commericial favorability.\",        caption = \"NOTE: Y-axis is on a log10 scale.\",        x = \"Level\",        y = \"Likes-to-Dislikes Ratio\") +   theme_bw() +   theme(legend.position = 'none',         text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.x = element_text(size = 12),         axis.text.y = element_text(size = 12))"},{"path":"/articles/Example_analysis.html","id":"to-what-extent-does-superbowl-commercial-favorability-vary-over-time-and-between-brands","dir":"Articles","previous_headings":"Analysis","what":"To what extent does superbowl commercial favorability vary over time and between brands?","title":"Example Analysis","text":"","code":"youtube.mod %>%   #filter(view_count > 1000) %>%   group_by(year) %>%   mutate(lmean = 10**mean(log10(like_to_dislike), na.rm = TRUE)) %>%   ggplot(aes(x = year, y = like_to_dislike)) +   geom_point(aes(size = view_group, color = view_factor), alpha = 0.75) +   geom_smooth(method = \"lm\", color = \"black\") +   scale_y_continuous(trans = 'log10') +   scale_size(guide = \"none\") +   scale_colour_discrete(na.translate = F) +   labs(title = \"Commercial Favorability over Time\",        subtitle = \"Favorability averages are relatively constant over time.\",        x = \"Year\",        y = \"Likes-to-Dislikes Ratio\",        caption = \"NOTE: Y-axis is on a log10 scale.\",        color = \"View Count\") +   theme_bw() +   theme(text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.x = element_text(size = 12),         axis.text.y = element_text(size = 12))  youtube.mod %>%   filter(!is.na(like_count)) %>%   ggplot(aes(x = fct_reorder(brand, like_to_dislike, .fun = median),               y = like_to_dislike)) +   geom_boxplot(outlier.shape = NA) +   geom_point(aes(size = view_group, color = view_factor), alpha = 0.75,              position=position_jitter(width=0.15)) +   scale_y_continuous(trans = 'log10') +   scale_size(guide = \"none\") +   labs(title = \"Commercial Favorability and Viewership by Brand\",         subtitle = \"Kia commericals had the highest average likes-to-dislikes ratio. \\n Doritos had the most commericals with > 1 million views.\",        x = \"Brand\",        y = \"Likes-to-Dislikes Ratio\",        color = \"View Count\",        caption = \"NOTE: Y-axis is on a log10 scale.\") +   theme_bw() +   theme(axis.text.x = element_text(size = 12, angle = -35),         text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.y = element_text(size = 12))"},{"path":"/articles/Example_analysis.html","id":"is-total-view-count-associated-commercial-favorability","dir":"Articles","previous_headings":"Analysis","what":"Is total view count associated commercial favorability?","title":"Example Analysis","text":"","code":"youtube.mod %>%   #filter(view_count > 1000) %>%   ggplot(aes(x = view_count, y = like_to_dislike)) +   geom_point(shape = 1) +   geom_smooth(method = \"lm\", color = \"black\") +   stat_poly_eq() +   scale_y_continuous(trans = 'log10') +   scale_x_continuous(trans = 'log10') +   labs(title = \"Commerical Favorability as a Function of View Count\",        subtitle = \"On average, higher viewiership is associated with greater favorability.\",        caption = \"NOTE: Y-axis is on a log10 scale.\",        x = \"View Count\",        y = \"Likes-to-Dislikes Ratio\") +   theme_bw() +     theme(text = element_text(size = 15),         plot.title = element_text(size = 20),         axis.text.x = element_text(size = 12),         axis.text.y = element_text(size = 12))"},{"path":"/articles/Example_analysis.html","id":"leaps-demonstration","dir":"Articles","previous_headings":"","what":"Leaps Demonstration","title":"Example Analysis","text":"Now want use multiple linear regression model commercial favorability. data matrix use model fitting. includes 9 predictor variables 1 response variable (.e., like_to_dislike_log10). don’t necessarily want use variable model, since lead fitting. Therefore, need decide subset variables maximize fit model preventing fitting. leaps comes . , use leaps::regsubsets apply model subset selection using exhaustive search algorithm. Given data matrix specified response variable, function fit multiple linear model every possible combination predictors returns best-fitting model model size. instance, provide 3 distinct predictor variables response variable, leaps::regsubsets return 3 separate models: best-fitting model using one variable, best-fitting model using two variables, full model.  plots outputted leaps::summary.regsubsets; summarize results leaps::regsubsets using 4 different goodness fit metrics: residual sum squares (RSS), Bayesian Information Criterion (BIC), adjusted R-squared, Mallow’s Cp. use adjusted R-squared goodness fit metric, lower left subplot tells us overall best-fitting model six predictor variables. see variables , run leaps::plot.regsubsets function.  can see , leaps::plot.regsubsets returned graphical depiction best fitting-models number predictor variables goodness--fit metric. Since using adjusted R-squared, want select model maximizes value. top row lower left subplot tells us following model maximizes adjusted R-squared: like_to_dislike_log10 ~ 1 + year + patriotic + animals + danger + celebrity + view_count_log10. Note model 6 predictor variables, consistent output leaps::summary.regsubsets. Now fit model maximizes adjusted R-squared using lm function.  running one-way ANOVA model, find significant sources variation like_to_dislike_log10 come view_count_log10, celebrity, danger. According model summary, model estimates , average: 10-fold increase view count associated approximately 50% increase like--dislike ratio. use danger commercial associated approximately 37% increase like--dislike ratio. use celebrities commercial associated approximately 80% increase like--dislike ratio. important note , based model diagnostic plots, really large really small like--dislike ratios tend overestimated. Therefore, extreme estimates like--dislike ratios taken grain salt.","code":"################################################################################ # Clean data frame before running model selection algo ################################################################################ youtube.subset <- youtube.mod %>%   #filter(view_count > 1000) %>%   select(year, funny, show_product_quickly, patriotic, animals, danger,           celebrity, use_sex, view_count_log10, like_to_dislike_log10) %>%   filter(!is.na(view_count_log10) & !is.na(like_to_dislike_log10))  glimpse(youtube.subset) #> Rows: 225 #> Columns: 10 #> $ year                  <int> 2018, 2020, 2006, 2018, 2003, 2020, 2020, 2020, … #> $ funny                 <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALS… #> $ show_product_quickly  <lgl> FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, FAL… #> $ patriotic             <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,… #> $ animals               <lgl> FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FAL… #> $ danger                <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, FAL… #> $ celebrity             <lgl> FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TR… #> $ use_sex               <lgl> FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, … #> $ view_count_log10      <dbl> 5.240372, 4.678992, 5.153235, 2.296665, 4.138018… #> $ like_to_dislike_log10 <dbl> 1.5002506, 1.5105450, 0.9098234, 0.4771213, 0.72… ################################################################################ # Create a regsubsets object and perform model selection with EXHAUSTIVE search  ################################################################################ mod.subsets <- leaps::regsubsets(like_to_dislike_log10 ~.,                    data = youtube.subset,                    force.in = NULL, force.out = NULL,                   method = \"exhaustive\")  ################################################################################ # Plot summary of output from regsubsets ################################################################################ mod.subsets.summary <- summary(mod.subsets)  par(mfrow = c(2,2))   plot(mod.subsets.summary$rss, xlab = \"Number of Variables\", ylab = \"RSS\", type = 'l')      plot(mod.subsets.summary$bic, xlab = \"Number of Variables\", ylab = \"BIC\", type = 'l')   points(3,mod.subsets.summary$bic[3],col=\"red\",cex=2,pch=20)      plot(mod.subsets.summary$adjr2, xlab = \"Number of Variables\", ylab = \"Adjusted RSq\", type = 'l')   points(6,mod.subsets.summary$adjr2[6],col=\"red\",cex=2,pch=20)      plot(mod.subsets.summary$cp, xlab = \"Number of Variables\", ylab = \"Cp\", type = 'l')   points(4,mod.subsets.summary$cp[4],col=\"red\",cex=2,pch=20) par(mfrow = c(2,2))   plot(mod.subsets, scale = \"bic\")   plot(mod.subsets, scale = \"r2\")   plot(mod.subsets, scale = \"adjr2\")   plot(mod.subsets, scale = \"Cp\") ################################################################################ # Build best fitting model and then summarize ################################################################################ mod <- lm(like_to_dislike_log10 ~ 1 + year + view_count_log10 + factor(patriotic) + factor(animals) + factor(danger) + factor(celebrity), data = youtube.subset)  anova(mod) #> Analysis of Variance Table #>  #> Response: like_to_dislike_log10 #>                    Df Sum Sq Mean Sq F value    Pr(>F)     #> year                1  0.217  0.2167  1.3252    0.2509     #> view_count_log10    1 11.875 11.8748 72.6086 2.623e-15 *** #> factor(patriotic)   1  0.416  0.4158  2.5427    0.1123     #> factor(animals)     1  0.136  0.1358  0.8301    0.3632     #> factor(danger)      1  0.644  0.6438  3.9367    0.0485 *   #> factor(celebrity)   1  2.815  2.8147 17.2107 4.795e-05 *** #> Residuals         218 35.653  0.1635                       #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 summary(mod) #>  #> Call: #> lm(formula = like_to_dislike_log10 ~ 1 + year + view_count_log10 +  #>     factor(patriotic) + factor(animals) + factor(danger) + factor(celebrity),  #>     data = youtube.subset) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.28987 -0.29451  0.05051  0.29388  0.90134  #>  #> Coefficients: #>                        Estimate Std. Error t value Pr(>|t|)     #> (Intercept)           19.042681   9.847909   1.934   0.0544 .   #> year                  -0.009441   0.004904  -1.925   0.0555 .   #> view_count_log10       0.186205   0.022667   8.215 1.87e-14 *** #> factor(patriotic)TRUE -0.086801   0.077537  -1.119   0.2642     #> factor(animals)TRUE    0.072989   0.057323   1.273   0.2043     #> factor(danger)TRUE     0.136440   0.060248   2.265   0.0245 *   #> factor(celebrity)TRUE  0.255151   0.061503   4.149 4.80e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.4044 on 218 degrees of freedom #> Multiple R-squared:  0.3111, Adjusted R-squared:  0.2922  #> F-statistic: 16.41 on 6 and 218 DF,  p-value: 1.402e-15 par(mfrow = c(2,2)) plot(mod)"},{"path":"/articles/Example_analysis.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Example Analysis","text":"Overall, analysis showed variations superbowl commercial favorability, measured like--dislike ratio, can explained part view count youtube, inclusion “dangerous” themes, inclusion celebrities. important note analysis conducted limited sample superbowl commercials provided Five-Thirty-Eight, findings analysis may generalize larger, representative sample.","code":""},{"path":"/articles/Example_analysis.html","id":"list-of-functions","dir":"Articles","previous_headings":"","what":"List of Functions","title":"Example Analysis","text":"dplyr: mutate, select, filter, group_by, summarize tidyr: pivot_longer ggplot2: geom_point, geom_line, geom_tile, geom_smooth, geom_boxplot, facet_wrap purrr: map, mapdf leaps: regsubsets, summary.regsubsets, plot.regsubsets","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Thomas Lumley. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Miller TLboFcbA (2020). leaps: Regression Subset Selection. R package version 3.1, https://CRAN.R-project.org/package=leaps.","code":"@Manual{,   title = {leaps: Regression Subset Selection},   author = {Thomas Lumley based on Fortran code by Alan Miller},   year = {2020},   note = {R package version 3.1},   url = {https://CRAN.R-project.org/package=leaps}, }"},{"path":"/index.html","id":"leaps--regression-subset-selection","dir":"","previous_headings":"","what":"Regression Subset Selection","title":"Regression Subset Selection","text":"Package Author: Thomas Lumley t.lumley@auckland.ac.nz Project Author: Josh Stim jstim1@jh.edu","code":""},{"path":"/index.html","id":"package-description","dir":"","previous_headings":"","what":"Package Description:","title":"Regression Subset Selection","text":"package performs exhaustive search best subsets given set potential regressors, using branch--bound algorithm, also performs searches using number less time-consuming techniques. designed replace “leaps()” command S. based FORTRAN77 code Alan Miller CSIRO Division Mathematics & Statistics, described detail book “Subset Selection Regression”. Parts code published Applied Statistics algorithms series. several minor useful improvements S implementation. Firstly, hard-coded limit number variables. Secondly, possible restrict search subsets specified size, potentially giving large saving time. Thirdly, necessary matrix possible predictors full rank. particularly useful predictors cases best “small” model wanted. Fourthly, many cases predictors, search can run output biglm() time memory use independent number observations.","code":""},{"path":"/index.html","id":"exported-classes-and-functions","dir":"","previous_headings":"","what":"Exported Classes and Functions:","title":"Regression Subset Selection","text":"leaps Subset selection `leaps bounds’ compatible S. “…performs exhaustive search best subsets variables x predicting y linear regression, using efficient branch--bound algorithm. compatibility wrapper regsubsets thing better.” - R Documentation regsubsets sophisticated function, including formula method “Model selection exhaustive search, forward backward stepwise, sequential replacement.” - R Documentation","code":""},{"path":"/index.html","id":"how-to-install","dir":"","previous_headings":"","what":"How to Install","title":"Regression Subset Selection","text":"","code":"install.packages(\"leaps\") library(leaps)"},{"path":"/index.html","id":"leaps-example","dir":"","previous_headings":"","what":"leaps Example:","title":"Regression Subset Selection","text":"","code":"x<-matrix(rnorm(100),ncol=4) y<-rnorm(25) leaps(x,y) ## $which ##       1     2     3     4 ## 1 FALSE FALSE  TRUE FALSE ## 1 FALSE  TRUE FALSE FALSE ## 1  TRUE FALSE FALSE FALSE ## 1 FALSE FALSE FALSE  TRUE ## 2 FALSE  TRUE  TRUE FALSE ## 2  TRUE FALSE  TRUE FALSE ## 2 FALSE FALSE  TRUE  TRUE ## 2  TRUE  TRUE FALSE FALSE ## 2 FALSE  TRUE FALSE  TRUE ## 2  TRUE FALSE FALSE  TRUE ## 3  TRUE  TRUE  TRUE FALSE ## 3 FALSE  TRUE  TRUE  TRUE ## 3  TRUE FALSE  TRUE  TRUE ## 3  TRUE  TRUE FALSE  TRUE ## 4  TRUE  TRUE  TRUE  TRUE ##  ## $label ## [1] \"(Intercept)\" \"1\"           \"2\"           \"3\"           \"4\"           ##  ## $size ##  [1] 2 2 2 2 3 3 3 3 3 3 4 4 4 4 5 ##  ## $Cp ##  [1] 1.681903 2.536230 6.654005 6.688600 1.337056 3.544980 3.631842 3.859235 ##  [9] 4.247740 8.348539 3.023003 3.323505 5.482288 5.658566 5.000000"},{"path":"/index.html","id":"regsubsets-example","dir":"","previous_headings":"","what":"regsubsets Example:","title":"Regression Subset Selection","text":"","code":"data(swiss) a<-regsubsets(as.matrix(swiss[,-1]),swiss[,1]) summary(a) b<-regsubsets(Fertility~.,data=swiss,nbest=2) summary(b)  coef(a, 1:3) vcov(a, 3) ## Subset selection object ## 5 Variables  (and intercept) ##                  Forced in Forced out ## Agriculture          FALSE      FALSE ## Examination          FALSE      FALSE ## Education            FALSE      FALSE ## Catholic             FALSE      FALSE ## Infant.Mortality     FALSE      FALSE ## 1 subsets of each size up to 5 ## Selection Algorithm: exhaustive ##          Agriculture Examination Education Catholic Infant.Mortality ## 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"              ## 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"              ## 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"              ## 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"              ## 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"              ## Subset selection object ## Call: UseMethod(\"regsubsets\",x) ## 5 Variables  (and intercept) ##                  Forced in Forced out ## Agriculture          FALSE      FALSE ## Examination          FALSE      FALSE ## Education            FALSE      FALSE ## Catholic             FALSE      FALSE ## Infant.Mortality     FALSE      FALSE ## 2 subsets of each size up to 5 ## Selection Algorithm: exhaustive ##          Agriculture Examination Education Catholic Infant.Mortality ## 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"              ## 1  ( 2 ) \" \"         \"*\"         \" \"       \" \"      \" \"              ## 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"              ## 2  ( 2 ) \" \"         \" \"         \"*\"       \" \"      \"*\"              ## 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"              ## 3  ( 2 ) \"*\"         \" \"         \"*\"       \"*\"      \" \"              ## 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"              ## 4  ( 2 ) \" \"         \"*\"         \"*\"       \"*\"      \"*\"              ## 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"              ## [[1]] ## (Intercept)   Education  ##  79.6100585  -0.8623503  ##  ## [[2]] ## (Intercept)   Education    Catholic  ##  74.2336892  -0.7883293   0.1109210  ##  ## [[3]] ##      (Intercept)        Education         Catholic Infant.Mortality  ##      48.67707330      -0.75924577       0.09606607       1.29614813  ##  ##                   (Intercept)     Education      Catholic Infant.Mortality ## (Intercept)      62.711883147 -0.2349982009 -0.0011120059     -2.952862263 ## Education        -0.234998201  0.0136416868  0.0004427309      0.003360365 ## Catholic         -0.001112006  0.0004427309  0.0007408169     -0.001716363 ## Infant.Mortality -2.952862263  0.0033603646 -0.0017163629      0.149759535"},{"path":"/reference/leaps.html","id":null,"dir":"Reference","previous_headings":"","what":"all-subsets regressiom — leaps","title":"all-subsets regressiom — leaps","text":"leaps() performs exhaustive search best subsets variables x predicting y linear regression, using efficient branch--bound algorithm.  compatibility wrapper regsubsets thing better. Since algorithm returns best model size, results depend penalty model model size: make difference whether want use AIC, BIC, CIC, DIC, ...","code":""},{"path":"/reference/leaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"all-subsets regressiom — leaps","text":"","code":"leaps(x=, y=, wt=rep(1, NROW(x)), int=TRUE, method=c(\"Cp\", \"adjr2\", \"r2\"), nbest=10,  names=NULL, df=NROW(x), strictly.compatible=TRUE)"},{"path":"/reference/leaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"all-subsets regressiom — leaps","text":"x matrix predictors y response vector wt Optional weight vector int Add intercept model method Calculate Cp, adjusted R-squared R-squared nbest Number subsets size report names vector names columns x df Total degrees freedom use instead nrow(x) calculating Cp adjusted R-squared strictly.compatible Implement misfeatures leaps() S","code":""},{"path":"/reference/leaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"all-subsets regressiom — leaps","text":"list components logical matrix. row can used select columns x respective model size Number variables, including intercept , model cp adjr2 r2 value chosen model   selection statistic model label vector names columns x","code":""},{"path":"/reference/leaps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"all-subsets regressiom — leaps","text":"Alan Miller \"Subset Selection Regression\" Chapman \\& Hall","code":""},{"path":"/reference/leaps.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"all-subsets regressiom — leaps","text":"strictly.compatible=T function stop error x full rank 31 columns. ignore column names x even names==NULL replace \"0\" \"9\", \"\" \"Z\".","code":""},{"path":[]},{"path":"/reference/leaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"all-subsets regressiom — leaps","text":"","code":"x<-matrix(rnorm(100),ncol=4) y<-rnorm(25) leaps(x,y) #> $which #>       1     2     3     4 #> 1  TRUE FALSE FALSE FALSE #> 1 FALSE FALSE  TRUE FALSE #> 1 FALSE FALSE FALSE  TRUE #> 1 FALSE  TRUE FALSE FALSE #> 2  TRUE FALSE FALSE  TRUE #> 2  TRUE FALSE  TRUE FALSE #> 2  TRUE  TRUE FALSE FALSE #> 2 FALSE FALSE  TRUE  TRUE #> 2 FALSE  TRUE  TRUE FALSE #> 2 FALSE  TRUE FALSE  TRUE #> 3  TRUE FALSE  TRUE  TRUE #> 3  TRUE  TRUE FALSE  TRUE #> 3  TRUE  TRUE  TRUE FALSE #> 3 FALSE  TRUE  TRUE  TRUE #> 4  TRUE  TRUE  TRUE  TRUE #>  #> $label #> [1] \"(Intercept)\" \"1\"           \"2\"           \"3\"           \"4\"           #>  #> $size #>  [1] 2 2 2 2 3 3 3 3 3 3 4 4 4 4 5 #>  #> $Cp #>  [1] -0.4093805  0.7001944  0.8350106  1.1794851  1.0999307  1.4703359 #>  [7]  1.5853731  2.4436672  2.6596585  2.8344474  3.0424059  3.0867598 #> [13]  3.4300362  4.4014995  5.0000000 #>"},{"path":"/reference/leaps.setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal functions for leaps(), subsets() — leaps.setup","title":"Internal functions for leaps(), subsets() — leaps.setup","text":"functions used internally regsubsets leaps. wrappers Fortran routines construct manipulate QR decomposition.","code":""},{"path":"/reference/leaps.setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal functions for leaps(), subsets() — leaps.setup","text":"","code":"leaps.setup(x,y,wt=rep(1,length(y)),force.in=NULL,force.out=NULL,intercept=TRUE,nvmax=8,   nbest=1,warn.dep=TRUE) leaps.seqrep(leaps.obj) leaps.exhaustive(leaps.obj,really.big=FALSE) leaps.backward(leaps.obj,nested) leaps.forward(leaps.obj,nested)"},{"path":"/reference/leaps.setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal functions for leaps(), subsets() — leaps.setup","text":"x matrix predictors y response vector wt Optional weight vector intercept Add intercept model force.vector indicating variable must model force.vector indicating variable must model nbest Number subsets size report nvmax largest subset size examine warn.dep warn x full rank leaps.obj object class leaps produced leaps.setup really.big required R gets sent long uninterruptible computation nested Use just forward backward selection models, models variables 1:nvmax constructed free setup","code":""},{"path":[]},{"path":"/reference/plot.regsubsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical table of best subsets — plot.regsubsets","title":"Graphical table of best subsets — plot.regsubsets","text":"Plots table models showing variables model. models ordered specified model selection statistic. plot  particularly useful ten models simple table  produced summary.regsubsets big read.","code":""},{"path":"/reference/plot.regsubsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical table of best subsets — plot.regsubsets","text":"","code":"# S3 method for regsubsets plot(x, labels=obj$xnames, main=NULL, scale=c(\"bic\", \"Cp\", \"adjr2\", \"r2\"), col=gray(seq(0, 0.9, length = 10)),...)"},{"path":"/reference/plot.regsubsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical table of best subsets — plot.regsubsets","text":"x regsubsets object labels variable names main title plot scale summary statistic use ordering plots col Colors: last color close distinct    white ... arguments","code":""},{"path":"/reference/plot.regsubsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical table of best subsets — plot.regsubsets","text":"None","code":""},{"path":"/reference/plot.regsubsets.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Graphical table of best subsets — plot.regsubsets","text":"Thomas Lumley, based concept Merlise Clyde","code":""},{"path":[]},{"path":"/reference/plot.regsubsets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical table of best subsets — plot.regsubsets","text":"","code":"data(swiss) a<-regsubsets(Fertility~.,nbest=3,data=swiss) par(mfrow=c(1,2)) plot(a) plot(a,scale=\"r2\")"},{"path":"/reference/regsubsets.html","id":null,"dir":"Reference","previous_headings":"","what":"functions for model selection — regsubsets","title":"functions for model selection — regsubsets","text":"Model selection exhaustive search, forward backward   stepwise, sequential replacement","code":""},{"path":"/reference/regsubsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"functions for model selection — regsubsets","text":"","code":"regsubsets(x=, ...)  # S3 method for formula regsubsets(x=, data=, weights=NULL, nbest=1, nvmax=8,  force.in=NULL, force.out=NULL, intercept=TRUE,  method=c(\"exhaustive\", \"backward\", \"forward\", \"seqrep\"),  really.big=FALSE,  nested=(nbest==1),...)  # S3 method for default regsubsets(x=, y=, weights=rep(1, length(y)), nbest=1, nvmax=8, force.in=NULL, force.out=NULL, intercept=TRUE,  method=c(\"exhaustive\",\"backward\", \"forward\", \"seqrep\"), really.big=FALSE,nested=(nbest==1),...)  # S3 method for biglm regsubsets(x,nbest=1,nvmax=8,force.in=NULL, method=c(\"exhaustive\",\"backward\", \"forward\", \"seqrep\"), really.big=FALSE,nested=(nbest==1),...)  # S3 method for regsubsets summary(object,all.best=TRUE,matrix=TRUE,matrix.logical=FALSE,df=NULL,...)  # S3 method for regsubsets coef(object,id,vcov=FALSE,...) # S3 method for regsubsets vcov(object,id,...)"},{"path":"/reference/regsubsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"functions for model selection — regsubsets","text":"x design matrix model formula full model, biglm object data Optional data frame y response vector weights weight vector nbest number subsets size record nvmax maximum size subsets examine force.index columns design matrix models force.index columns design matrix models intercept Add intercept? method Use exhaustive search, forward selection, backward selection sequential replacement search. really.big Must TRUE perform exhaustive search   50 variables. nested See Note : nested=FALSE, models   columns 1, 1 2, 1-3, , also considered object regsubsets object .best Show best subsets just one size matrix Show matrix variables model just summary     statistics matrix.logical matrix=TRUE, matrix logical     TRUE/FALSE string \"*\"/\" \" df Specify number degrees freedom summary   statistics. default n-1 id model models (ordered summary output)   return coefficients variance matrix vcov TRUE, return variance-covariance matrix attribute ... arguments future methods","code":""},{"path":"/reference/regsubsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"functions for model selection — regsubsets","text":"Since function returns separate best models sizes nvmax since different model selection criteria AIC, BIC, CIC, DIC, ... differ models different sizes compared, results depend choice cost-complexity tradeoff. x biglm object assumed full model, force.relevant. intercept forced default; specify force.logical vector FALSE first element allow intercept dropped. model search actually fit model, returned object contain coefficients standard errors.  Coefficients variance-covariance matrix one model models can obtained coef vcov methods.","code":""},{"path":"/reference/regsubsets.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"functions for model selection — regsubsets","text":"part setup process, code initially fits models first variable x, first two, first three, . forward backward selection possible model k first variables better model k variables selection algorithm. , model first k variables returned, warning. can happen forward backward selection. (obviously) exhaustive search. nbest=1 can avoid extra models   nested=TRUE, default.","code":""},{"path":"/reference/regsubsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"functions for model selection — regsubsets","text":"regsubsets returns object class \"regsubsets\" containing user-serviceable parts. designed processed summary.regsubsets. summary.regsubsets returns object elements logical matrix indicating elements   model rsq r-squared model rss Residual sum squares model adjr2 Adjusted r-squared cp Mallows' Cp bic Schwartz's information criterion, BIC outmat version component formatted   printing obj copy regsubsets object coef method returns coefficient vector list vectors, vcov method returns matrix list matrices.","code":""},{"path":[]},{"path":"/reference/regsubsets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"functions for model selection — regsubsets","text":"","code":"data(swiss) a<-regsubsets(as.matrix(swiss[,-1]),swiss[,1]) summary(a) #> Subset selection object #> 5 Variables  (and intercept) #>                  Forced in Forced out #> Agriculture          FALSE      FALSE #> Examination          FALSE      FALSE #> Education            FALSE      FALSE #> Catholic             FALSE      FALSE #> Infant.Mortality     FALSE      FALSE #> 1 subsets of each size up to 5 #> Selection Algorithm: exhaustive #>          Agriculture Examination Education Catholic Infant.Mortality #> 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"              #> 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"              #> 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"              #> 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"              #> 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"              b<-regsubsets(Fertility~.,data=swiss,nbest=2) summary(b) #> Subset selection object #> Call: eval(expr, envir, enclos) #> 5 Variables  (and intercept) #>                  Forced in Forced out #> Agriculture          FALSE      FALSE #> Examination          FALSE      FALSE #> Education            FALSE      FALSE #> Catholic             FALSE      FALSE #> Infant.Mortality     FALSE      FALSE #> 2 subsets of each size up to 5 #> Selection Algorithm: exhaustive #>          Agriculture Examination Education Catholic Infant.Mortality #> 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"              #> 1  ( 2 ) \" \"         \"*\"         \" \"       \" \"      \" \"              #> 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"              #> 2  ( 2 ) \" \"         \" \"         \"*\"       \" \"      \"*\"              #> 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"              #> 3  ( 2 ) \"*\"         \" \"         \"*\"       \"*\"      \" \"              #> 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"              #> 4  ( 2 ) \" \"         \"*\"         \"*\"       \"*\"      \"*\"              #> 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"               coef(a, 1:3) #> [[1]] #> (Intercept)   Education  #>  79.6100585  -0.8623503  #>  #> [[2]] #> (Intercept)   Education    Catholic  #>  74.2336892  -0.7883293   0.1109210  #>  #> [[3]] #>      (Intercept)        Education         Catholic Infant.Mortality  #>      48.67707330      -0.75924577       0.09606607       1.29614813  #>  vcov(a, 3) #>                   (Intercept)     Education      Catholic Infant.Mortality #> (Intercept)      62.711883147 -0.2349982009 -0.0011120059     -2.952862263 #> Education        -0.234998201  0.0136416868  0.0004427309      0.003360365 #> Catholic         -0.001112006  0.0004427309  0.0007408169     -0.001716363 #> Infant.Mortality -2.952862263  0.0033603646 -0.0017163629      0.149759535"}]
